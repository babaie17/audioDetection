<!doctype html>
<html lang="en">
<head>
  <meta charset="utf-8" />
  <title>Mic ‚Üí Cloud ASR (Top 5)</title>
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <style>
    :root { --bg:#0b1020; --card:#141a2e; --accent:#7aa2ff; --text:#e8ecff; --muted:#a6b0d6; }
    html,body { height:100%; margin:0; font-family: system-ui, -apple-system, Segoe UI, Roboto, Arial, "Helvetica Neue", sans-serif; background:var(--bg); color:var(--text); }
    .wrap { max-width: 760px; margin: 40px auto; padding: 24px; background:var(--card); border-radius: 16px; box-shadow: 0 10px 30px rgba(0,0,0,.35); }
    h1 { margin:0 0 16px; font-size: 22px; }
    .row { display:flex; gap:12px; align-items:center; flex-wrap:wrap; }
    select, button { background:#1b2340; color:var(--text); border:1px solid #2a3766; border-radius: 10px; padding:10px 12px; font-size:15px; }
    select:focus, button:focus { outline: 2px solid var(--accent); outline-offset: 2px; }
    button.mic { font-weight:600; border-radius: 999px; padding:14px 18px; display:inline-flex; align-items:center; gap:10px; }
    button.mic.recording { background: #b42334; border-color: #ff8a9b; }
    .status { margin-top: 14px; color: var(--muted); min-height: 1.4em; }
    .results { margin-top: 16px; background:#0f1630; border:1px solid #29376b; border-radius: 12px; padding: 12px; }
    .results h3 { margin: 0 0 8px; font-size:15px; color: var(--muted); }
    .list { display:flex; flex-direction:column; gap:8px; }
    .item { background:#121a38; border:1px solid #2a3766; border-radius: 10px; padding:10px 12px; }
    .provider { margin-left:auto; font-size:12px; color:var(--muted); }
    .controls { display:flex; gap:10px; align-items:center; }
    .pill { background:#0c1330; border:1px solid #26407a; padding:7px 10px; border-radius:999px; color:var(--muted); font-size:12px; }
    .note { margin-top:10px; color:#aab4e4; font-size:13px; }
    .error { color:#ff9aa4; }
  </style>
</head>
<body>
  <div class="wrap">
    <h1>Cloud Speech Test (Top-5)</h1>

    <div class="row">
      <label for="lang">Language:</label>
      <select id="lang">
        <option value="en-US" selected>English (United States)</option>
        <option value="zh-CN">‰∏≠ÊñáÔºàÊôÆÈÄöËØùÔºå‰∏≠ÂõΩÔºâ</option>
        <option value="zh-TW">‰∏≠ÊñáÔºàÂúãË™ûÔºåÂè∞ÁÅ£Ôºâ</option>
        <option value="ja-JP">Êó•Êú¨Ë™û</option>
        <option value="ko-KR">ÌïúÍµ≠Ïñ¥</option>
        <option value="es-ES">Espa√±ol (Espa√±a)</option>
      </select>

      <div class="controls">
        <span class="pill" title="Select which cloud to use">
          Provider:
          <select id="provider" style="background:transparent;border:none;color:var(--text);">
            <option value="azure" selected>Azure (Top-5)</option>
            <option value="openai">OpenAI (1-best)</option>
          </select>
        </span>
      </div>
    </div>

    <div class="status" id="status">Idle.</div>

    <div class="results" id="results" hidden>
      <h3>Most probable results</h3>
      <div class="list" id="list"></div>
    </div>

    <div style="margin-top:16px;">
      <button id="micBtn" class="mic" type="button" aria-pressed="false">
        üéôÔ∏è <span id="micLabel">Start Recording</span>
      </button>
      <span class="provider" id="provInfo"></span>
    </div>

    <div class="note">
      Tip: click once to start, again to stop. Short utterances (&lt;10s) work best.
    </div>
  </div>
    <script src="/js/pinyin-loader.js"></script>
    <script>
    const langSel = document.getElementById('lang');
    const providerSel = document.getElementById('provider');
    const statusEl = document.getElementById('status');
    const micBtn = document.getElementById('micBtn');
    const micLabel = document.getElementById('micLabel');
    const resultsBox = document.getElementById('results');
    const listEl = document.getElementById('list');
    const provInfo = document.getElementById('provInfo');
  
    let recording = false;
    let MODE = null;        // 'wav' or 'media'
    let mediaRecorder = null, chunks = [];

    // --- helpers to detect a single Hanzi / single pinyin ---
    function isSingleHanChar(s) {
      return [...(s||'')].filter(ch => /\p{Script=Han}/u.test(ch)).length === 1;
    }
    function normalizePinyinKey(s) {
      const toneMap = {'ƒÅ':'a1','√°':'a2','«é':'a3','√†':'a4','ƒì':'e1','√©':'e2','ƒõ':'e3','√®':'e4','ƒ´':'i1','√≠':'i2','«ê':'i3','√¨':'i4','≈ç':'o1','√≥':'o2','«í':'o3','√≤':'o4','≈´':'u1','√∫':'u2','«î':'u3','√π':'u4','«ñ':'v1','«ò':'v2','«ö':'v3','«ú':'v4','√º':'v'};
      let t = (s||'').trim().toLowerCase();
      t = t.replace(/[ƒÅ√°«é√†ƒì√©ƒõ√®ƒ´√≠«ê√¨≈ç√≥«í√≤≈´√∫«î√π«ñ«ò«ö«ú√º]/g, m=>toneMap[m]||m);
      if (!/^[a-z]+[1-5]?$/.test(t) || t.includes(' ') || t.length>6) return null;
      return t; // "hao" or "hao3"
    }
  
    // --- render homophones under your results list ---
    function renderHomophones(zhAugment) {
      if (!zhAugment || !Array.isArray(zhAugment.homophones) || zhAugment.homophones.length === 0) return;
      const { mode, input, bases, homophones } = zhAugment;
  
      const box = document.createElement('div');
      box.className = 'item';
  
      const head = document.createElement('div');
      head.style.marginBottom = '6px';
      head.style.opacity = '.85';
      head.textContent = mode === 'singleChar'
        ? `Homophones for ${input}${bases?.length?` [${bases.join(', ')}]`:''}:`
        : `Characters for "${input}"${bases?.length?` [${bases.join(', ')}]`:''}:`;
      box.appendChild(head);
  
      const chips = document.createElement('div');
      chips.style.display = 'flex';
      chips.style.flexWrap = 'wrap';
      chips.style.gap = '8px';
  
      homophones.slice(0, 64).forEach(ch => {
        const span = document.createElement('span');
        span.style.padding = '6px 9px';
        span.style.border = '1px solid #2a3766';
        span.style.borderRadius = '8px';
        span.style.background = '#101735';
        span.textContent = ch;
        chips.appendChild(span);
      });
  
      box.appendChild(chips);
      listEl.appendChild(box);
    }
      
    function setStatus(msg, isError=false) {
      statusEl.textContent = msg;
      statusEl.className = 'status' + (isError ? ' error' : '');
    }
    function setRecording(on) {
      recording = on;
      micBtn.classList.toggle('recording', on);
      micBtn.setAttribute('aria-pressed', on ? 'true' : 'false');
      micLabel.textContent = on ? 'Stop Recording' : 'Start Recording';
      provInfo.textContent = `Using: ${providerSel.value.toUpperCase()}`;
    }
    function renderCandidates(arr) {
      const clean = Array.isArray(arr)
        ? arr.map(s => (s || '').trim()).filter(Boolean).slice(0, 5)
        : [];
      listEl.innerHTML = '';
      resultsBox.hidden = false;
      if (clean.length === 0) {
        const div = document.createElement('div');
        div.className = 'item';
        div.textContent = 'No speech recognized. Try a slightly longer/clearer utterance.';
        listEl.appendChild(div);
        return;
      }
      clean.forEach((t, i) => {
        const div = document.createElement('div');
        div.className = 'item';
        div.textContent = `${i+1}. ${t}`;
        listEl.appendChild(div);
      });
    }
  
    /* ---------- WAV recorder (Azure) ---------- */
    const WAV = { ctx:null, stream:null, source:null, processor:null, buffers:[], sampleRate:16000, recording:false };
    async function startWavRecording() {
      WAV.stream = await navigator.mediaDevices.getUserMedia({ audio:true });
      WAV.ctx = new (window.AudioContext || window.webkitAudioContext)({ sampleRate: WAV.sampleRate });
      WAV.source = WAV.ctx.createMediaStreamSource(WAV.stream);
      WAV.processor = WAV.ctx.createScriptProcessor(4096, 1, 1);
      WAV.buffers = [];
      WAV.processor.onaudioprocess = (e) => {
        WAV.buffers.push(new Float32Array(e.inputBuffer.getChannelData(0)));
      };
      WAV.source.connect(WAV.processor);
      WAV.processor.connect(WAV.ctx.destination);
      WAV.recording = true;
    }
    function stopWavRecording() {
      return new Promise(resolve => {
        if (!WAV.recording) return resolve(null);
        WAV.recording = false;
        try { WAV.processor.disconnect(); } catch {}
        try { WAV.source.disconnect(); } catch {}
        try { WAV.stream.getTracks().forEach(t => t.stop()); } catch {}
  
        // merge Float32 buffers
        const totalLen = WAV.buffers.reduce((a,c)=>a+c.length, 0);
        const data = new Float32Array(totalLen);
        let off = 0; for (const b of WAV.buffers) { data.set(b, off); off += b.length; }
  
        // Float32 -> Int16 PCM
        const pcm = new Int16Array(data.length);
        for (let i=0;i<data.length;i++) {
          const s = Math.max(-1, Math.min(1, data[i]));
          pcm[i] = s < 0 ? s * 0x8000 : s * 0x7FFF;
        }
  
        // Build WAV header
        const numChannels = 1, bitsPerSample = 16, sampleRate = WAV.sampleRate;
        const byteRate = sampleRate * numChannels * (bitsPerSample/8);
        const blockAlign = numChannels * (bitsPerSample/8);
        const dataSize = pcm.byteLength;
  
        const buf = new ArrayBuffer(44 + dataSize);
        const dv = new DataView(buf);
        let p = 0;
        writeStr('RIFF'); u32(36 + dataSize); writeStr('WAVE'); writeStr('fmt '); u32(16);
        u16(1); u16(numChannels); u32(sampleRate); u32(byteRate); u16(blockAlign); u16(bitsPerSample);
        writeStr('data'); u32(dataSize);
        new Uint8Array(buf, 44).set(new Uint8Array(pcm.buffer));
  
        function writeStr(s){ for (let i=0;i<s.length;i++) dv.setUint8(p++, s.charCodeAt(i)); }
        function u16(v){ dv.setUint16(p, v, true); p+=2; }
        function u32(v){ dv.setUint32(p, v, true); p+=4; }
  
        const blob = new Blob([buf], { type: 'audio/wav' });
        resolve(blob);
      });
    }
  
    /* ---------- MediaRecorder (OpenAI) ---------- */
    async function startMediaRecording() {
      const stream = await navigator.mediaDevices.getUserMedia({ audio:true });
      chunks = [];
  
      // Prefer WebM/Opus for OpenAI; fallback to OGG/Opus if needed
      let mime = '';
      if (MediaRecorder.isTypeSupported('audio/webm;codecs=opus')) {
        mime = 'audio/webm;codecs=opus';
      } else if (MediaRecorder.isTypeSupported('audio/ogg;codecs=opus')) {
        mime = 'audio/ogg;codecs=opus';
      } else {
        mime = ''; // let browser decide
      }
  
      mediaRecorder = new MediaRecorder(stream, mime ? { mimeType: mime } : undefined);
      mediaRecorder.ondataavailable = e => { if (e.data && e.data.size) chunks.push(e.data); };
      mediaRecorder.start();
    }
    function stopMediaRecording() {
      return new Promise(resolve => {
        if (!mediaRecorder) return resolve(null);
        mediaRecorder.onstop = () => {
          const type = chunks[0]?.type || 'application/octet-stream';
          const blob = new Blob(chunks, { type });
          // Stop tracks
          try { mediaRecorder.stream.getTracks().forEach(t => t.stop()); } catch {}
          resolve(blob);
        };
        mediaRecorder.stop();
      });
    }
  
    /* ---------- Common upload ---------- */
    async function sendToServer(audioBlob) {
      const ext =
        audioBlob.type.includes('wav') ? 'wav' :
        audioBlob.type.includes('webm') ? 'webm' :
        audioBlob.type.includes('ogg') ? 'ogg' : 'bin';
  
      const form = new FormData();
      form.append('audio', audioBlob, `speech.${ext}`);
      form.append('language', langSel.value);
      form.append('provider', providerSel.value);
      form.append('debug','1'); // uncomment for a single request if you want upstream diagnostics
  
      const r = await fetch('/api/transcribe', { method: 'POST', body: form });
      const ct = r.headers.get('content-type') || '';
      if (ct.includes('application/json')) {
        const data = await r.json();
        if (!r.ok) {
          const msg = typeof data.error === 'string' ? data.error : JSON.stringify(data.error || data);
          throw new Error(msg);
        }
        return data;
      } else {
        const text = await r.text();
        throw new Error(text || `HTTP ${r.status}`);
      }
    }
  
    micBtn.addEventListener('click', async () => {
      try {
        if (!recording) {
          // Choose recorder by provider
          if (providerSel.value === 'azure') {
            MODE = 'wav';
            await startWavRecording();
          } else {
            MODE = 'media';
            await startMediaRecording();
          }
          setRecording(true);
          setStatus('Listening‚Ä¶');
        } else {
          setStatus('Processing‚Ä¶');
          let blob = null;
          if (MODE === 'wav') {
            blob = await stopWavRecording();
          } else {
            blob = await stopMediaRecording();
          }
          setRecording(false);
          if (!blob) { setStatus('No audio captured.', true); return; }
  
          const data = await sendToServer(blob);
          console.log('API response:', data);
  
          const candidates = Array.isArray(data.candidates) ? data.candidates : [];
          renderCandidates(candidates);

          // 1) Server-provided homophones (only if non-empty)
          if (data.zhAugment && Array.isArray(data.zhAugment.homophones) && data.zhAugment.homophones.length > 0) {
            renderHomophones(data.zhAugment);
          }
          
          // 2) Client fallback using pinyin-loader.js (runs if server gave none)
          try {
            const top = (candidates[0] || '').trim();
            const langPrimary = (langSel.value||'').split('-')[0];
            if (langPrimary === 'zh' && top) {
              // Strip common Chinese punctuation from edge cases like "‰Ω†„ÄÇ"
              const onlyHan = [...top].filter(ch => /\p{Script=Han}/u.test(ch)).join('');
              // Case A: single Hanzi -> ask loader for its readings and list homophones
              if (onlyHan && onlyHan.length === 1 && window.pinyinLoader?.homophonesFromHanzi) {
                const homos = await window.pinyinLoader.homophonesFromHanzi(onlyHan);
                if (homos && homos.length) renderHomophones({ mode:'singleChar', input: onlyHan, bases: null, homophones: homos });
              } else {
                // Case B: single pinyin syllable -> list characters directly
                const key = normalizePinyinKey(top);
                if (key && window.pinyinLoader?.homophonesFromPinyin) {
                  const homos = await window.pinyinLoader.homophonesFromPinyin(key);
                  if (homos && homos.length) renderHomophones({ mode:'singlePinyin', input: top, bases: [key.replace(/[1-5]$/,'')], homophones: homos });
                }
              }
            }
          } catch (e) {
            console.warn('client fallback failed:', e);
          }
          
          if (data.debug) console.log('DEBUG upstream:', data);
          setStatus(`Done. Received ${candidates.length} result(s).`);
        }
      } catch (err) {
        console.error(err);
        setRecording(false);
        setStatus(err.message || 'Error', true);
      }
    });
  </script>
</body>
</html>
